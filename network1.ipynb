{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Networks to Recognize Handwritten Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will build a Multi-layer Percepteron as the architecture for our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the MNIST Dataset for training our network. It contains 60,000 training images, and 10,000 test images.\n",
    "\n",
    "The loading and handling of the training images is done in a seperate file - mnist_loader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will build our first neural network and use stochastic gradient descent as the learning method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will use the sigmoid activation function. The hyperparameters are the no. of epochs, η, no. of neurons/units in each layer and the no. of layers itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on, some notational background:\n",
    "- Epochs: Stochastic gradient descent works by picking out a randomly chosen mini-batch of training imputs and training the \n",
    "  weights and biases with those. Then we pick out another randomly chosen mini-batch and train with those and so on               until we have exhausted the training inputs, which is said to complete a epoch of training\n",
    "- η/eta - This is the learning rate. If it is too small, training will be very slow and if it is too large, the flactuations             will be wild and convergence to the minimum will be very erratic, if any. \n",
    "- No. of layers - We can control the complexity by changing the no. of layers in our network.\n",
    "- No. of neurons - We will always use 10 neurons in the output layer: one to represent each digit.\n",
    "- Cost function - The loss function we'll use is the Mean Square Losee (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will start by building our network now, all the methods are explained in the docstrings, and the rest are explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "            \n",
    "        return a\n",
    "    \n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "\n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "                \n",
    "            if test_data:\n",
    "                print(\"Epoch {} : {} / {}\".format(j,self.evaluate(test_data),n_test));\n",
    "            else:\n",
    "                print(\"Epoch {} complete\".format(j))\n",
    "                \n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            # Adds the change in weight and biase required for each training example in mini-batch into nabla_b and nabla_w\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        \n",
    "        # 3) Gradient Descent/ updating the weights and biases\n",
    "        # v′ = v − η/m∇C\n",
    "        self.weights = [w- (eta/len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b- (eta/len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "        \n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # 1) Input\n",
    "        activation = x\n",
    "        activations = [x]          # List to store all the activations, layer by layer\n",
    "        zs = []                    # List to store all the z vectors, layer by layer\n",
    "        \n",
    "        # 2a) Feedforward\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "            \n",
    "        # 2b) Backward pass/ Output Error\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        # 2c) Backpropogate the error for each layer \n",
    "        for l in range(2, self.num_layers):\n",
    "            # Calculate error of second to last layer, than third to last layer and so on for all layers, backwards\n",
    "            z = zs[-l]                               \n",
    "            sp = sigmoid_prime(z)        # Derivative of simoid activation function\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp    # δ(l) =((w(l+1)^T * δ(l+1)) ⊙ σ′(z(l))\n",
    "            nabla_b[-l] = delta                                           # ∂C/∂b(l) = δ\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())    # ∂C/∂w(l) = a(l−1) * δ(l)\n",
    "            \n",
    "        return (nabla_b, nabla_w)                       # Returns change in weights and biases for single training example\n",
    "    \n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        \n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        \n",
    "        return (output_activations-y)\n",
    "\n",
    "# Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The equation applied by the feed-forward method is: a′= σ(wa + b)\n",
    "       where w is the weight matrix \n",
    "             b is the bias vector\n",
    "          \n",
    "- SGD method: The training_data is a list of tuples (x, y) representing the training inputs and corresponding desired outputs\n",
    "   If the optional argument test_data is supplied, then the program will evaluate the network after each epoch of training, and    print out partial progress.\n",
    "   \n",
    "  In each epoch, it starts by randomly shuffling the training data, and then partitions it into mini-batches of the appropriate size. Then for each mini_batch we apply a single step of gradient descent. This is done by the code self.update_mini_batch(mini_batch, eta), which updates the network weights and biases according to a single iteration of gradient descent, using just the training data in mini_batch.\n",
    "  \n",
    "  \n",
    "- update_mini_batch method: The most important line is delta_nabla_b, delta_nabla_w = self.backprop(x, y) which invokes the backpropagation algorithim for computing the gradients of the cost function. backprop method returns the appropriate gradient for the cost associated to the training example x.\n",
    "\n",
    "\n",
    "- backprop method: Described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation Algorithim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is about understanding how changing the weights and biases in a network changes the cost function. Ultimately, this means computing the partial derivatives ∂C/∂w and ∂C/∂b. \n",
    "But to compute those, we first introduce an intermediate quantity, δ, which we call the error and we will compute it as avector for each layer.\n",
    "\n",
    "The error, δ, is simply ∂C/∂a^L * σ′(z^L) (where we are multiplying how fast the cost is changing w.r.t last layer activation and how fast theactivation is changing.) \n",
    "\n",
    "Notation: z = wa+b\n",
    "\n",
    "           where w is the weight matrix \n",
    "           b is the bias vector\n",
    "           \n",
    "a(L) means the activation of the last layer.\n",
    "δ(l) means the error of the layer number l."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The equations for backpropagation\n",
    "\n",
    "1) An equation for the error in the output layer, δL:\n",
    "   δL = ∂C / ∂aL * σ′(z(L))\n",
    "   \n",
    "   or \n",
    "   \n",
    "   δL = ∇aC ⊙ σ′(z(L))       \n",
    "               \n",
    "               ∇aC: is defined to be a vector whose components are the partial derivatives ∂C/∂aL\n",
    "               You can think of ∇aC as expressing the rate of change of C with respect to the output activations.\n",
    "               \n",
    "               ∇aC = (a(L)−y) as C = 1/2 * ∥y − a(L)∥^2\n",
    "               \n",
    "               ⊙ - is the Hadamard product, i.e. the component by component product of the vectors\n",
    "   \n",
    "2) An equation for the error δ(l) in terms of the error in the next layer, δ(l+1):\n",
    "    δ(l) = ((wl+1)^T * δ(l+1)) ⊙ σ′(z(l))\n",
    "    \n",
    "                \n",
    "        When we apply the transpose weight matrix, (wl+1)T, we can think intuitively of this as moving the error backward      \n",
    "        through the network, giving us some sort of measure of the error at the output of the lth layer. We then take the \n",
    "        Hadamard product ⊙σ′(zl). This moves the error backward through the activation function in layer l, giving us the error\n",
    "        δ(l) in the weighted input to layer l.\n",
    "        \n",
    "        \n",
    "3) An equation for the rate of change of the cost with respect to any bias in the network:\n",
    "    ∂C/∂b = δ\n",
    "    \n",
    "4) An equation for the rate of change of the cost with respect to any weight in the network:\n",
    "    ∂C/∂w(l) = a(l−1) * δ(l)\n",
    "    \n",
    "- Note: Equations 3 and 4 are the main equations and it these that go into the ∇C gradient vector during gradient descent\n",
    "    v′ = v − η∇C\n",
    "    Equations 1 and 2 are just intermidiates and that help us to compute equations 3 and 4.\n",
    "\n",
    "\n",
    "###### All these equations are obtained by chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithim: \n",
    "\n",
    "1) Input x: Set the corresponding activation a1 for the input layer.\n",
    "\n",
    "2) Feedforward: For each l=2,3,…,L compute z = wa + b and a = σ(z).\n",
    "\n",
    "3) Output error δ(L): Compute the vector δ(L) = ∇aC ⊙ σ′(z(L)); this is the output vector of the last layer.\n",
    "\n",
    "4) Backpropagate the error: For each l=L−1,L−2,…,2 compute δ(l) =((w(l+1)T * δ(l+1)) ⊙ σ′(z(l)).\n",
    "\n",
    "5) Output: The gradient of the cost function is given by ∂C/∂w(l) = a(l−1) * δ(l) and ∂C/∂b(l) = δ(l).\n",
    "\n",
    "We compute the error vectors δ(l) backward, starting from the final layer. To understand how the cost varies with earlier weights and biases we need to repeatedly apply the chain rule, working backward through the layers to obtain usable expressions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### The backpropagation algorithm computes the gradient of the cost function for a single training example.\n",
    "\n",
    "We combine backpropagation with stochastic gradient descent, in which we compute the gradient for many training examples. In particular, given a mini-batch of m training examples, the following algorithm applies a gradient descent learning step based on that mini-batch:\n",
    "\n",
    "1) Input a set of training examples\n",
    "\n",
    "2) For each training example x: Set the corresponding input activation a(x,1), and perform the following steps:\n",
    "\n",
    "        2a) Feedforward: For each l=2,3,…,L compute z = wa + b and a = σ(z).\n",
    "        \n",
    "        2b) Output error δ(x,L): Compute the vector δ(x,L) = ∇aCx ⊙ σ′(z(x,L))\n",
    "        \n",
    "        2c) Backpropagate the error: For each l=L−1,L−2,…,2 compute δ(x,l) = ((wl+1)T * δ(x,l+1)) ⊙ σ′(z(x,l))\n",
    "        \n",
    "3) Gradient descent: For each l=L,L−1,…,2 update the weights and biases using ∂C/∂w and ∂C/∂b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phew! Well, now let us take a look at how our model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by loading in the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network A with 30 hidden neurons (95% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We will set up a Network with 30 neurons in the single hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784, 30, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll use stochastic gradient descent to learn from the MNIST training_data over 30 epochs, with a mini-batch size of 10, and a learning rate of η=3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 9079 / 10000\n",
      "Epoch 1 : 9217 / 10000\n",
      "Epoch 2 : 9308 / 10000\n",
      "Epoch 3 : 9254 / 10000\n",
      "Epoch 4 : 9357 / 10000\n",
      "Epoch 5 : 9356 / 10000\n",
      "Epoch 6 : 9401 / 10000\n",
      "Epoch 7 : 9417 / 10000\n",
      "Epoch 8 : 9384 / 10000\n",
      "Epoch 9 : 9428 / 10000\n",
      "Epoch 10 : 9455 / 10000\n",
      "Epoch 11 : 9442 / 10000\n",
      "Epoch 12 : 9455 / 10000\n",
      "Epoch 13 : 9449 / 10000\n",
      "Epoch 14 : 9461 / 10000\n",
      "Epoch 15 : 9473 / 10000\n",
      "Epoch 16 : 9461 / 10000\n",
      "Epoch 17 : 9454 / 10000\n",
      "Epoch 18 : 9447 / 10000\n",
      "Epoch 19 : 9475 / 10000\n",
      "Epoch 20 : 9471 / 10000\n",
      "Epoch 21 : 9485 / 10000\n",
      "Epoch 22 : 9475 / 10000\n",
      "Epoch 23 : 9493 / 10000\n",
      "Epoch 24 : 9476 / 10000\n",
      "Epoch 25 : 9463 / 10000\n",
      "Epoch 26 : 9462 / 10000\n",
      "Epoch 27 : 9489 / 10000\n",
      "Epoch 28 : 9471 / 10000\n",
      "Epoch 29 : 9482 / 10000\n"
     ]
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The accuracy we get with a single hidden layer with 10 hidden neurons is 94.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network B with 100 hidden neurons (97% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Changing the number of hidden neurons to 100 increases the complexity of the the neural net and thus we are expecting a bump to our 95% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Network([784, 100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 5667 / 10000\n",
      "Epoch 1 : 6629 / 10000\n",
      "Epoch 2 : 6827 / 10000\n",
      "Epoch 3 : 7590 / 10000\n",
      "Epoch 4 : 7617 / 10000\n",
      "Epoch 5 : 7688 / 10000\n",
      "Epoch 6 : 8624 / 10000\n",
      "Epoch 7 : 8687 / 10000\n",
      "Epoch 8 : 9483 / 10000\n",
      "Epoch 9 : 9554 / 10000\n",
      "Epoch 10 : 9533 / 10000\n",
      "Epoch 11 : 9561 / 10000\n",
      "Epoch 12 : 9579 / 10000\n",
      "Epoch 13 : 9591 / 10000\n",
      "Epoch 14 : 9614 / 10000\n",
      "Epoch 15 : 9618 / 10000\n",
      "Epoch 16 : 9619 / 10000\n",
      "Epoch 17 : 9627 / 10000\n",
      "Epoch 18 : 9628 / 10000\n",
      "Epoch 19 : 9616 / 10000\n",
      "Epoch 20 : 9627 / 10000\n",
      "Epoch 21 : 9657 / 10000\n",
      "Epoch 22 : 9636 / 10000\n",
      "Epoch 23 : 9649 / 10000\n",
      "Epoch 24 : 9651 / 10000\n",
      "Epoch 25 : 9660 / 10000\n",
      "Epoch 26 : 9642 / 10000\n",
      "Epoch 27 : 9660 / 10000\n",
      "Epoch 28 : 9660 / 10000\n",
      "Epoch 29 : 9653 / 10000\n"
     ]
    }
   ],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "net2.SGD(training_data, 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As expected, increasing the number of neurons results an improvement in the perfomance of our network as the accuracy improves from 94.8% to 96.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
